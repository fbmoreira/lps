---
title: "Proposal-Final"
author: "Francis Moreira"
date: "November 30, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R markdown document to work on the analysis of CBBT(Critical Basic Block Transition)-defined phases on the jpeg compression application (cjpeg) from miBench, using Fursin et al's set of inputs.
First, let's load the libraries:

```{r}
library(tidyverse)
library(ggplot2)
```


Now let's download the files to make sure we have them in the working directory:

```{r}
file = "cjpeg_training_behavior_traces.csv"
if(!file.exists(file)){
  download.file("http://www.opendatapoa.com.br/storage/f/2013-11-06T17%3A38%3A06.476Z/acidentes-2003.csv",
	destfile=file)
}

df_train <- read_csv("cjpeg_training_behavior_traces.csv")

file = "cjpeg_classification_traces.csv"
if(!file.exists(file)){
  download.file("http://www.opendatapoa.com.br/storage/f/2013-11-06T17%3A38%3A06.476Z/acidentes-2003.csv",
	destfile=file)
}

df_classification <- read_csv("cjpeg_classification_traces.csv")


```


let's analyze the data to make sure it has been correctly parsed:

```{r}
head(df_classification)
summary(df_classification)
```


```{r}
head(df_train)
summary(df_train)
```

note: DO NOT SAVE R DATA!!! These tables are huge, and will take a long time to load, regardless on whether you save the data on R or not.

So let's pose some questions from the proposal.
First, "Is there any phase in all of the inputs with a different combination of
"Number of Basic Block executions" and "Number of Unique Basic Block
executions" which is NOT found in S?"

Basically, we need to group by phase, and check for each phase in the classification df whether a "number of unique BBLs" in the phase exists for that phase in the training df.

First, let's observe the behavior a bit:

```{r}
library(ggplot2)

disttrain <- df_train %>% group_by(srcbbl,destbbl) %>% distinct(numuniqbbls) %>% dplyr::summarize(count = n()) %>% mutate(phase_id = paste(srcbbl,destbbl))

disttrain

disttrain %>% ggplot(aes(x=phase_id, y=count)) + geom_col() + theme_bw() + 
  labs(x = "CBBT phases", 
       y = "Number of False Positives",
       title = "False Positives using number of unique BBLs to characterize normal behavior") +
       theme(axis.ticks.x = element_blank(),
             axis.text.x = element_blank(),
             panel.grid.major.x = element_blank()) +
        scale_y_continuous(breaks=c(0,2,4,6,8,10,15,20,25),
                     limits=c(0,25)) +
        scale_x_discrete()

```

woah, some phases have a very large number of different behaviors... 

Now before we run the full table, we can facilitate this a bit. We only care whether a phase behavior is present in classification and not present in train, so we don't care about repetition at all. Furthermore, the question asks about the number of unique bbls, so we can drop the number of bbls column:

```{r}
summ_classification <- df_classification %>% group_by(srcbbl,destbbl) %>% select(-c(numbbls)) %>% distinct()
summ_train <- df_train %>% group_by(srcbbl,destbbl)  %>% select(-c(numbbls)) %>% distinct()
```

Much smaller! So this should run much faster!
First let's check data integrity:

```{r}
summary(summ_classification)
```

```{r}
summary(summ_train)
```

seems ok, some slight differences.. let's run the code now:

```{r}
test <- setdiff(summ_classification,summ_train)
test;
```

whoa! 58 rows in classification do not show up in training.
We can check an individual row with match_df from plyr:

```{r}
library(plyr)
rowtofind <- data.frame(srcbbl=4278115,destbbl=4278140, numuniqbbls=105)
match_df(summ_train,rowtofind)
match_df(summ_classification,rowtofind)
```

As we can see, the training set does not exhibit all the behaviors that a phase can express in the cjpeg application.
What is the percentage of false positives?

```{r}
58/nrow(df_classification)
```
But if we consider out of the number of phases...
```{r}
anphases <- test %>% select(-c(numuniqbbls)) %>% distinct() %>% nrow()
totphases <- summ_classification %>% select(-c(numuniqbbls)) %>% distinct() %>% nrow()
zeroit <- anphases/totphases;
```

That's a large number of phases deviating from the training behavior!
Therefore, we need to be a bit less restrictive.
Does any phase in the classification have a number of unique bbls larger than the MAXIMUM found during training?

We can now reduce summ_train to the maximum value of each phase.

```{r}
max_train <- summ_train %>% group_by(srcbbl,destbbl) %>% filter (numuniqbbls == max(numuniqbbls)) %>% arrange(srcbbl,destbbl,numuniqbbls)

max_train;

```


Now we look how many times each phase had a number of unique bbls larger than what was shown during training phase.
To work on the same table, it's better to rename the column on one table and join them:

```{r}
max_train <- max_train %>% dplyr::rename(maxuniqbbls = numuniqbbls)
dummy <- left_join(summ_classification,max_train ) 
max_train
```


```{r}
test <- dummy %>% filter(numuniqbbls > maxuniqbbls)
test
```

Here we can see that there were 23 instances in the classification traces of phases where the number of unique bbls was larger than what was detected in that phase during training.

```{r}
anphases <-test %>% group_by(srcbbl,destbbl) %>% select(srcbbl,destbbl) %>% distinct() %>% nrow()
firstit <- anphases/totphases
```

10% of the phases have a number of unique bbls larger than what has been seen during training.

By how much did they exceed the threshold found in the training?

```{r}
test %>% mutate(diff = numuniqbbls - maxuniqbbls) %>% mutate(id = paste(srcbbl,destbbl)) %>% ggplot(aes(x=id, y=diff)) + geom_col()+
  labs(x = "CBBT phases", 
       y = "Difference",
       title = "Difference between Unique BBLs found in testing and Maximum in Training") +
       theme_bw() +
       theme(axis.ticks.x = element_blank(),
             axis.text.x = element_blank(),
             panel.grid.major.x = element_blank()) +
        scale_y_continuous(breaks=c(0,2,4,6,8,10,12),
                     limits=c(0,12)) +
        scale_x_discrete()
```

Most phases have a very small deviation, which is probably within some noise of the phase.
However, a few phases have a high difference, which cannot be explained by noise alone.

Second question:

Is there any phase sequence P1 - P2 in all of the inputs which is not seen
in S?

First, we have to create new columns with the phase that comes after it.
```{r}

seqclass <- df_classification %>% mutate( seqsrcbbl = lead(srcbbl) ) %>% mutate(seqdestbbl = lead(destbbl))
seqclass
```


```{r}
seqtrain <- df_train %>% mutate ( seqsrcbbl = lead(srcbbl)) %>% mutate(seqdestbbl = lead(destbbl))
seqtrain
```

Now we can reduce the datasets to the different phases which follow a given phase:

```{r}
difftrainphase <- seqtrain %>% group_by(srcbbl,destbbl) %>% select(-c(numbbls,numuniqbbls)) %>% distinct()
difftrainphase

diffclassphase <- seqclass %>% group_by(srcbbl,destbbl) %>% select(-c(numbbls,numuniqbbls)) %>% distinct()
diffclassphase
```

What is the "fan-out" (distinct following phases) of each phase?

```{r}
fanout <- diffclassphase %>%  group_by(srcbbl,destbbl) %>% dplyr::summarise(count = n()) %>% mutate(id = paste(srcbbl,destbbl)) 

fanout %>% ggplot(aes(x=id, y=count)) + geom_col() + 
          labs(x = "CBBT phases", 
       y = "Number of Distinct Follow-up CBBTs",
       title = "Number of Distinct Follow-up CBBT phases for each CBBT phase") +
       theme_bw() +
       theme(axis.ticks.x = element_blank(),
             axis.text.x = element_blank(),
             panel.grid.major.x = element_blank()) +
        scale_y_continuous(breaks=c(0,2,4,6,8,10,12,14),
                     limits=c(0,14)) +
        scale_x_discrete()
summary(fanout)
```

now the question becomes: is there a phase sequence in classification which is not present in the training traces?

```{r}
anoms <- setdiff(diffclassphase,difftrainphase)
anoms
```

Thus we obtain 20 different phase sequences which appear in the classification traces but do not appear in the training traces.
False positive ratio regarding all CBBT-phase executions:

```{r}
20/nrow(df_classification)
```

False positive ratio regarding all distinct phases:
```{r}
anphases <- anoms %>% group_by(srcbbl,destbbl) %>% select(-c(seqsrcbbl,seqdestbbl)) %>% distinct() %>% nrow()
secondit <- anphases/totphases
```

Only slightly better than deviation from max number of uniq bbls.

Final Question:

Is there any combination or correlation of the features which can reliably
define normal behavior for all inputs?

As we have seen, we must restrict what constitutes an anomaly even further to lower the number of false positives.
So we will apply both conditions: an anomalous phase must have a number of unique bbls larger than what has been seen for any instance of that phase during training, AND its transition to the next phase must not exist in the training traces.

Basically, we have to merge the above codes:

```{r}
largedf <- left_join(seqclass,dummy)
largedf
```


```{r}
test <- largedf %>% filter(numuniqbbls > maxuniqbbls) %>% select(-c(numbbls,numuniqbbls,maxuniqbbls)) %>% setdiff(difftrainphase)
test
```

Thus we have a single phase with 2 different anomalous behavior instances.

False positive ratio:
```{r}
thirdit <- 1/totphases
```


```{r}
falsepos_df <- data.frame(falsepos = c(zeroit,firstit,secondit,thirdit),
                          type = c("#unique bbls",">max trained #unique bbls","phase sequence","combined" ))
falsepos_df %>% ggplot(aes(x=fct_relevel(type,
                   "#unique bbls",
                   ">max trained #unique bbls",
                   "phase sequence",
                   "combined"),y=falsepos)) + geom_col() + 
       labs(x = "Detection Methodology", 
       y = "False Positive Ratio",
       title = "Ratio of CBBT phases which are labeled as anomalous for each methodology") +
       theme_bw() +
       theme(axis.text.x = element_text(angle = 90,
                                   hjust = 1, vjust = 0),
             axis.ticks.x = element_blank(),
             panel.grid.major.x = element_blank()) +
       # scale_y_continuous(breaks=c(0.0,0.05,0.1,0.15,0.2,0.25),
                     #limits=c(0.0,0.25)) 
        scale_x_discrete()

```


The false positive bars indicate the progression of being ever-more restrictive on what constitutes an anomaly in the jpeg compression program. The ratio for the "combined" is quite acceptable, as in other benchmarks we found no other false positives.
However, the issue is that since training is random, we might just have been lucky.
The training phase needs to be changed to ensure maximum code/path coverage, so that different transitions between bbls can be observed inside each CBBT. To this end we will use paradyn in the future to obtain a full control flow graph from a statically linked binary, so we can have a complete training.
